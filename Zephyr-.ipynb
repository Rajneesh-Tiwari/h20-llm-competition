{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ba78d5-06be-4c3f-8d93-c5b1ad276a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType # type: ignore\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold,StratifiedGroupKFold\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "from __future__ import annotations\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, LlamaForSequenceClassification, MistralForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from sklearn.metrics import log_loss\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from shutil import rmtree\n",
    "from scipy.special import softmax\n",
    "import gc\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2416a088-226f-4109-99b0-1fb53fbd5e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ['TRANSFORMERS_CACHE'] = '///mnt/c/Personal/Competitions/HFCache/'\n",
    "os.environ['HF_HOME'] = '///mnt/c/Personal/Competitions/HFCache/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc7a1e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # General settings\n",
    "    EXP_NAME = 'nb006'\n",
    "    competition_name = 'h2O_llm'\n",
    "    seed = 2022 #42\n",
    "    debug = False\n",
    "    train = True\n",
    "    n_fold = 5\n",
    "    TARGET_MODEL = 'HuggingFaceH4/zephyr-7b-beta' #\"mistralai/Mistral-7B-Instruct-v0.1\" #\"mistralai/Mistral-7B-v0.1\"\n",
    "    DEBUG = False\n",
    "    max_len = 2048\n",
    "    \n",
    "CFG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eea2a5a-dba4-4b83-b477-69329a5cf1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed, use_cuda = True):\n",
    "    np.random.seed(seed) # cpu vars\n",
    "    torch.manual_seed(seed) # cpu  vars\n",
    "    random.seed(seed) # Python\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) # Python hash building\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cb5739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"///mnt/c/Personal/Competitions/Kaggle/h2oai-predict-the-llm/\"\n",
    "OUTPUT_DIR = f'///mnt/c/Personal/Competitions/Kaggle/h2oai-predict-the-llm/runs/' + CFG.EXP_NAME + \"/\"\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "train = pd.read_csv(data_dir + \"train.csv\").rename(columns={'target': 'label'})\n",
    "test = pd.read_csv(data_dir + \"test.csv\")\n",
    "sample_submission = pd.read_csv(data_dir + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a9e7b6-beec-41a6-a11f-2929c6183915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Response</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explain the concept of coevolution.</td>\n",
       "      <td>Coevolution is a biological process that occur...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is it possible that recurring fever and chills...</td>\n",
       "      <td>Yes, recurring fever and chills can be a sympt...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Evaluate the expression 3!</td>\n",
       "      <td>The expression 3! represents the factorial of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the roles of different types of RNA i...</td>\n",
       "      <td>1. Messenger RNA (mRNA): mRNA carries genetic ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the role of gene flow in population ge...</td>\n",
       "      <td>Gene flow refers to the movement of individual...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0                Explain the concept of coevolution.   \n",
       "1  Is it possible that recurring fever and chills...   \n",
       "2                         Evaluate the expression 3!   \n",
       "3  What are the roles of different types of RNA i...   \n",
       "4  What is the role of gene flow in population ge...   \n",
       "\n",
       "                                            Response  label  \n",
       "0  Coevolution is a biological process that occur...      3  \n",
       "1  Yes, recurring fever and chills can be a sympt...      4  \n",
       "2  The expression 3! represents the factorial of ...      1  \n",
       "3  1. Messenger RNA (mRNA): mRNA carries genetic ...      3  \n",
       "4  Gene flow refers to the movement of individual...      3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8790bea-0126-4ef1-8c96-1f2329786ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['Question'] = train['Question'].str.replace('\\n', '')\n",
    "# train['Response'] = train['Response'].str.replace('\\n', '')\n",
    "# test['Question'] = test['Question'].str.replace('\\n', '')\n",
    "# test['Response'] = test['Response'].str.replace('\\n', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd737f80-00ce-48e5-b46d-c4584003ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = StratifiedGroupKFold(n_splits=CFG.n_fold,shuffle=True,random_state=CFG.seed)\n",
    "\n",
    "for i, (_, val_index) in enumerate(gkf.split(train, train[\"label\"],groups=train['Question'])):\n",
    "    train.loc[val_index, \"fold\"] = i\n",
    "\n",
    "train = train.fillna(\"NA\")\n",
    "test = test.fillna(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "552609d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['all_text'] = 'Question: ' + train.Question + '; Answer: ' + train.Response\n",
    "test['all_text'] = 'Question: ' + test.Question + '; Answer: ' + test.Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "374c348c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"v_proj\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50246e07-0ad2-4c29-ba8d-69ed603c0d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = softmax(predictions,axis=1)\n",
    "    print(predictions)\n",
    "    logloss_val = log_loss(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        \"logloss\": logloss_val,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75ec3c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fld):\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(CFG.TARGET_MODEL, use_fast=False)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    # LlamaForSequenceClassification(\n",
    "    base_model = MistralForSequenceClassification.from_pretrained(\n",
    "        CFG.TARGET_MODEL,\n",
    "        num_labels=7,\n",
    "        cache_dir='///mnt/c/Personal/Competitions/HFCache/',\n",
    "        quantization_config=bnb_config,\n",
    "        device_map={\"\":0})\n",
    "    \n",
    "    # base_model.config.pretraining_tp = 1 # 1 is 7b\n",
    "    base_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    model = get_peft_model(base_model, peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "\n",
    "    train_df = train[train['fold']!=fld].reset_index(drop=True)\n",
    "    valid_df = train[train['fold']==fld].reset_index(drop=True)\n",
    "\n",
    "    print('train shape:',train_df.shape, 'valid shape:',valid_df.shape)\n",
    "    # from pandas\n",
    "    train_ds = Dataset.from_pandas(train_df)\n",
    "    valid_ds = Dataset.from_pandas(valid_df)\n",
    "\n",
    "    def preprocess_function(examples, max_length=CFG.max_len):\n",
    "        return tokenizer(examples[\"all_text\"], \n",
    "                         truncation=True, \n",
    "                         max_length=max_length, \n",
    "                         padding=True)\n",
    "\n",
    "    train_tokenized_ds = train_ds.map(preprocess_function, batched=True)\n",
    "    valid_tokenized_ds = valid_ds.map(preprocess_function, batched=True)\n",
    "\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")    \n",
    "    model_fold_dir = os.path.join(OUTPUT_DIR,str(fld)) \n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=model_fold_dir,\n",
    "        learning_rate=3e-4,#5e-5,\n",
    "        per_device_train_batch_size=1,\n",
    "        per_device_eval_batch_size=1,\n",
    "        gradient_accumulation_steps=32,\n",
    "        max_grad_norm=0.3,\n",
    "        optim='paged_adamw_32bit',\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        num_train_epochs=5,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        push_to_hub=False,\n",
    "        warmup_steps=100,\n",
    "        eval_steps=50,\n",
    "        save_steps = 50,\n",
    "        logging_steps=50,\n",
    "        report_to='none' # if DEBUG else 'wandb',\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_tokenized_ds,\n",
    "        eval_dataset=valid_tokenized_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "\n",
    "    trainer.save_model(output_dir=str(model_fold_dir))\n",
    "    \n",
    "    for path in Path(training_args.output_dir).glob(\"checkpoint-*\"):\n",
    "        if path.is_dir():\n",
    "            rmtree(path)\n",
    "            \n",
    "    del trainer, model, base_model\n",
    "\n",
    "    for i in range(5):\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "233f21ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea5201033734414a0dd99ca4b0502a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/638 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b081c4fb255646e4b8a9773248a5f678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc9772ef9114e3289fd387559dd5c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MistralForSequenceClassification were not initialized from the model checkpoint at HuggingFaceH4/zephyr-7b-beta and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,873,088 || all params: 7,117,533,184 || trainable%: 0.09656559122829936\n",
      "train shape: (3178, 5) valid shape: (798, 5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94cc4dd459b41f192760192b23c2f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07aecc45336a41efbb8e90468539bde3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 2:14:08, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>7.618900</td>\n",
       "      <td>2.658203</td>\n",
       "      <td>2.619318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.054600</td>\n",
       "      <td>1.399414</td>\n",
       "      <td>1.399243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.290300</td>\n",
       "      <td>1.291992</td>\n",
       "      <td>1.289160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.134600</td>\n",
       "      <td>0.985840</td>\n",
       "      <td>0.986463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.778300</td>\n",
       "      <td>0.957520</td>\n",
       "      <td>0.959075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.697500</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>0.941624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>3.322266</td>\n",
       "      <td>1.897734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.306900</td>\n",
       "      <td>1.293945</td>\n",
       "      <td>1.208485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>2.351562</td>\n",
       "      <td>1.629028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1106   0.005875 0.0353   ... 0.3271   0.1847   0.1193  ]\n",
      " [0.0879   0.011696 0.00208  ... 0.629    0.02641  0.10565 ]\n",
      " [0.08856  0.01159  0.02502  ... 0.3208   0.2471   0.1234  ]\n",
      " ...\n",
      " [0.4905   0.004883 0.02036  ... 0.0214   0.04913  0.263   ]\n",
      " [0.06824  0.008026 0.02342  ... 0.489    0.1583   0.1656  ]\n",
      " [0.0802   0.001928 0.00964  ... 0.2678   0.306    0.2607  ]]\n",
      "[[0.1076   0.261    0.2505   ... 0.0826   0.02719  0.03152 ]\n",
      " [0.0277   0.013084 0.007633 ... 0.03165  0.862    0.02043 ]\n",
      " [0.1521   0.0769   0.1174   ... 0.5913   0.01301  0.02979 ]\n",
      " ...\n",
      " [0.0875   0.2566   0.03708  ... 0.06445  0.209    0.2644  ]\n",
      " [0.0953   0.0745   0.1704   ... 0.5977   0.015144 0.04053 ]\n",
      " [0.002062 0.012985 0.008194 ... 0.007145 0.958    0.004505]]\n",
      "[[2.2266e-01 1.1774e-01 3.5278e-01 ... 1.1584e-01 4.3564e-03 2.2369e-02]\n",
      " [1.8356e-02 1.5076e-01 3.4904e-03 ... 1.0544e-02 2.4707e-01 1.8265e-02]\n",
      " [6.5039e-01 2.2545e-03 1.1023e-01 ... 2.2363e-01 8.2636e-04 1.0506e-02]\n",
      " ...\n",
      " [1.2577e-05 2.7039e-02 5.3644e-07 ... 4.2915e-06 5.9242e-03 1.2913e-03]\n",
      " [2.9443e-01 2.0790e-03 1.5869e-01 ... 5.3320e-01 9.0790e-04 9.9564e-03]\n",
      " [4.8492e-02 2.1411e-01 3.2684e-02 ... 4.2700e-01 1.6748e-01 1.0535e-01]]\n",
      "[[3.359e-03 3.363e-02 1.797e-03 ... 1.223e-04 1.748e-03 1.349e-02]\n",
      " [1.836e-02 7.202e-02 7.820e-03 ... 1.525e-02 8.457e-01 3.523e-03]\n",
      " [4.639e-01 1.834e-02 1.917e-01 ... 2.571e-01 7.153e-03 5.692e-02]\n",
      " ...\n",
      " [2.666e-04 3.721e-03 3.552e-05 ... 1.996e-04 9.883e-01 2.209e-04]\n",
      " [2.115e-01 5.096e-03 2.253e-01 ... 5.488e-01 6.952e-04 6.992e-03]\n",
      " [3.785e-05 5.636e-04 5.603e-06 ... 4.679e-05 9.990e-01 4.572e-05]]\n",
      "[[2.313e-05 1.203e-02 6.962e-05 ... 2.325e-06 1.421e-03 3.572e-03]\n",
      " [9.006e-05 1.420e-03 2.409e-04 ... 4.983e-04 9.971e-01 1.352e-04]\n",
      " [5.791e-01 1.825e-04 2.969e-01 ... 1.147e-01 1.454e-04 8.423e-03]\n",
      " ...\n",
      " [5.960e-08 1.371e-05 5.960e-08 ... 2.384e-07 1.000e+00 8.345e-07]\n",
      " [3.066e-01 1.807e-04 3.340e-01 ... 3.562e-01 2.002e-04 2.487e-03]\n",
      " [1.132e-06 2.673e-04 8.166e-06 ... 1.281e-05 9.990e-01 3.471e-04]]\n",
      "[[7.1645e-05 8.4457e-03 9.7930e-05 ... 7.7486e-07 2.0099e-04 4.0550e-03]\n",
      " [5.7709e-02 3.4644e-01 1.0944e-01 ... 5.8960e-02 3.7671e-01 1.4442e-02]\n",
      " [4.3140e-01 8.6288e-03 3.7036e-01 ... 1.8811e-01 1.3590e-04 1.5497e-03]\n",
      " ...\n",
      " [5.7340e-05 1.0567e-03 1.2636e-05 ... 1.2934e-05 9.9902e-01 3.9995e-05]\n",
      " [1.4233e-01 1.0843e-03 2.3425e-01 ... 6.2158e-01 6.6698e-05 3.9577e-04]\n",
      " [3.9935e-06 4.6897e-04 9.2387e-06 ... 2.1458e-05 9.9902e-01 4.1604e-05]]\n",
      "[[0.0000e+00 0.0000e+00 0.0000e+00 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [8.2275e-02 0.0000e+00 6.6260e-01 ... 2.5537e-01 0.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [1.7881e-07 0.0000e+00 1.1235e-04 ... 1.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajneesh/miniconda3/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000e+00 0.000e+00 0.000e+00 ... 0.000e+00 0.000e+00 5.960e-08]\n",
      " [7.337e-05 2.139e-01 2.260e-04 ... 1.009e-03 7.397e-01 4.923e-05]\n",
      " [8.027e-01 5.364e-07 1.484e-01 ... 4.895e-02 5.960e-08 5.007e-06]\n",
      " ...\n",
      " [0.000e+00 0.000e+00 0.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [7.935e-04 0.000e+00 5.817e-03 ... 9.932e-01 0.000e+00 0.000e+00]\n",
      " [0.000e+00 0.000e+00 0.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajneesh/miniconda3/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000e+00 0.000e+00 0.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [0.000e+00 5.299e-03 5.960e-08 ... 0.000e+00 9.941e-01 0.000e+00]\n",
      " [9.922e-01 0.000e+00 8.133e-03 ... 3.093e-05 0.000e+00 0.000e+00]\n",
      " ...\n",
      " [0.000e+00 0.000e+00 0.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [2.412e-04 0.000e+00 1.264e-03 ... 9.980e-01 0.000e+00 0.000e+00]\n",
      " [0.000e+00 0.000e+00 0.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajneesh/miniconda3/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbce75447c1f4f8fa636e9ab257f226c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MistralForSequenceClassification were not initialized from the model checkpoint at HuggingFaceH4/zephyr-7b-beta and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,873,088 || all params: 7,117,533,184 || trainable%: 0.09656559122829936\n",
      "train shape: (3178, 5) valid shape: (798, 5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2010798c6e704b4a819c989bd59d5ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809ee271b2b44717b4f17208ba6f4716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 2:13:59, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>6.278000</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>1.937405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.167700</td>\n",
       "      <td>2.285156</td>\n",
       "      <td>2.213167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.942900</td>\n",
       "      <td>1.824219</td>\n",
       "      <td>1.812596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.837300</td>\n",
       "      <td>1.694336</td>\n",
       "      <td>1.693922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.715700</td>\n",
       "      <td>1.640625</td>\n",
       "      <td>1.640927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.588100</td>\n",
       "      <td>1.526367</td>\n",
       "      <td>1.526646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.459100</td>\n",
       "      <td>1.474609</td>\n",
       "      <td>1.472436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.367000</td>\n",
       "      <td>1.420898</td>\n",
       "      <td>1.420640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.208000</td>\n",
       "      <td>1.396484</td>\n",
       "      <td>1.395767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1918  0.0425  0.2103  ... 0.1833  0.1136  0.1726 ]\n",
      " [0.0892  0.07043 0.2267  ... 0.1769  0.0738  0.1249 ]\n",
      " [0.0865  0.1365  0.1533  ... 0.2128  0.1355  0.0871 ]\n",
      " ...\n",
      " [0.11206 0.065   0.198   ... 0.1558  0.1442  0.1141 ]\n",
      " [0.1353  0.05103 0.1395  ... 0.4758  0.04382 0.1328 ]\n",
      " [0.10443 0.0809  0.142   ... 0.1592  0.1187  0.10724]]\n",
      "[[7.0679e-02 1.3892e-01 1.5588e-01 ... 1.2396e-01 3.0469e-01 1.3123e-01]\n",
      " [6.0608e-02 1.4026e-01 1.3782e-01 ... 9.8816e-02 3.4399e-01 9.3689e-02]\n",
      " [1.8402e-02 1.5308e-01 8.2458e-02 ... 3.5339e-02 3.8062e-01 4.2206e-02]\n",
      " ...\n",
      " [1.2970e-02 1.5540e-01 7.9163e-02 ... 2.9678e-02 4.0088e-01 3.6133e-02]\n",
      " [1.8677e-01 7.6914e-04 1.4294e-01 ... 7.6180e-03 1.0908e-05 6.5186e-01]\n",
      " [9.4376e-03 1.4905e-01 5.8563e-02 ... 2.4384e-02 3.8428e-01 3.3051e-02]]\n",
      "[[0.0777  0.18    0.2532  ... 0.1566  0.1519  0.1482 ]\n",
      " [0.0824  0.2194  0.3003  ... 0.1394  0.149   0.0752 ]\n",
      " [0.04868 0.2485  0.339   ... 0.03152 0.1509  0.0594 ]\n",
      " ...\n",
      " [0.06033 0.2595  0.2773  ... 0.0516  0.1729  0.08154]\n",
      " [0.1149  0.1306  0.1838  ... 0.1826  0.1619  0.2108 ]\n",
      " [0.05328 0.255   0.3093  ... 0.03552 0.134   0.0697 ]]\n",
      "[[0.1449  0.05328 0.1085  ... 0.295   0.1738  0.2053 ]\n",
      " [0.11115 0.0905  0.1099  ... 0.294   0.2568  0.1046 ]\n",
      " [0.074   0.0809  0.0942  ... 0.03946 0.5137  0.0799 ]\n",
      " ...\n",
      " [0.0599  0.065   0.0872  ... 0.03004 0.5527  0.06204]\n",
      " [0.2659  0.0616  0.0742  ... 0.2004  0.2012  0.1837 ]\n",
      " [0.05432 0.08057 0.1004  ... 0.034   0.4937  0.0665 ]]\n",
      "[[0.2422  0.02133 0.1764  ... 0.274   0.12036 0.1401 ]\n",
      " [0.253   0.05222 0.1614  ... 0.2898  0.1378  0.0628 ]\n",
      " [0.1692  0.05215 0.1561  ... 0.03102 0.4053  0.0574 ]\n",
      " ...\n",
      " [0.1687  0.06384 0.1365  ... 0.0234  0.402   0.0369 ]\n",
      " [0.3762  0.02934 0.0968  ... 0.2634  0.1282  0.09375]\n",
      " [0.0684  0.06067 0.11383 ... 0.0111  0.4038  0.02797]]\n",
      "[[0.1471   0.02908  0.2163   ... 0.2384   0.1399   0.202   ]\n",
      " [0.1311   0.157    0.1918   ... 0.1394   0.1873   0.0712  ]\n",
      " [0.03723  0.07825  0.11584  ... 0.006756 0.668    0.0368  ]\n",
      " ...\n",
      " [0.01639  0.1042   0.0796   ... 0.00877  0.7246   0.02917 ]\n",
      " [0.3003   0.0582   0.09686  ... 0.3362   0.0716   0.1208  ]\n",
      " [0.01834  0.1182   0.05917  ... 0.004654 0.6963   0.05212 ]]\n",
      "[[0.1877   0.03275  0.0829   ... 0.2488   0.116    0.3054  ]\n",
      " [0.0656   0.1707   0.1678   ... 0.12427  0.09247  0.04178 ]\n",
      " [0.03687  0.11816  0.3013   ... 0.00856  0.367    0.03998 ]\n",
      " ...\n",
      " [0.013336 0.10254  0.0956   ... 0.004627 0.4685   0.02846 ]\n",
      " [0.4546   0.04553  0.05624  ... 0.2979   0.0444   0.0906  ]\n",
      " [0.02933  0.0895   0.1548   ... 0.004944 0.3972   0.03925 ]]\n",
      "[[0.1829   0.02655  0.0653   ... 0.1909   0.1659   0.356   ]\n",
      " [0.1332   0.1564   0.1664   ... 0.2083   0.0839   0.05124 ]\n",
      " [0.05878  0.0911   0.2119   ... 0.004364 0.4817   0.03305 ]\n",
      " ...\n",
      " [0.02428  0.04617  0.0793   ... 0.005272 0.568    0.0223  ]\n",
      " [0.499    0.04184  0.02876  ... 0.312    0.0466   0.06494 ]\n",
      " [0.04086  0.0595   0.142    ... 0.003588 0.4624   0.02893 ]]\n",
      "[[1.3123e-01 3.4912e-02 6.4758e-02 ... 1.5686e-01 1.5601e-01 4.5117e-01]\n",
      " [7.2510e-02 2.7954e-01 1.9141e-01 ... 1.1188e-01 9.9976e-02 2.4368e-02]\n",
      " [1.4412e-02 1.0614e-01 1.6785e-01 ... 3.8695e-04 6.5234e-01 1.0025e-02]\n",
      " ...\n",
      " [3.4428e-03 2.8503e-02 3.3295e-02 ... 3.2282e-04 7.3193e-01 4.8943e-03]\n",
      " [6.3428e-01 3.7567e-02 2.0950e-02 ... 2.1997e-01 4.2816e-02 4.2572e-02]\n",
      " [9.0485e-03 5.2063e-02 1.2720e-01 ... 3.4666e-04 5.0195e-01 1.4572e-02]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074b91686f654dfd94229b9f13dcd057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MistralForSequenceClassification were not initialized from the model checkpoint at HuggingFaceH4/zephyr-7b-beta and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,873,088 || all params: 7,117,533,184 || trainable%: 0.09656559122829936\n",
      "train shape: (3178, 5) valid shape: (798, 5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e70ee55ff5f4e12a28371b3faee338a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e66bf27539544189153e41483004db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 2:19:37, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>6.094300</td>\n",
       "      <td>2.132812</td>\n",
       "      <td>2.012540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.111900</td>\n",
       "      <td>1.994141</td>\n",
       "      <td>1.932809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.284700</td>\n",
       "      <td>1.088867</td>\n",
       "      <td>1.088517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.094100</td>\n",
       "      <td>1.103516</td>\n",
       "      <td>1.102558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.797200</td>\n",
       "      <td>1.132812</td>\n",
       "      <td>1.134392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.759100</td>\n",
       "      <td>1.033203</td>\n",
       "      <td>1.033628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.329800</td>\n",
       "      <td>1.112305</td>\n",
       "      <td>1.095750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.284800</td>\n",
       "      <td>0.974609</td>\n",
       "      <td>0.970695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>1.445312</td>\n",
       "      <td>1.341999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.3313e-02 8.5526e-03 2.0623e-05 ... 3.7785e-03 2.5094e-05 9.0283e-01]\n",
      " [2.3666e-02 3.6646e-01 1.1139e-03 ... 1.0658e-02 2.3758e-02 3.4912e-02]\n",
      " [1.6220e-02 2.5757e-01 3.5205e-01 ... 9.9258e-03 2.6880e-01 8.4290e-02]\n",
      " ...\n",
      " [1.2671e-01 3.5840e-01 1.6724e-01 ... 1.0223e-01 8.9355e-02 1.2169e-02]\n",
      " [8.2324e-01 1.7761e-02 1.5221e-03 ... 8.7097e-02 1.4900e-02 3.8872e-03]\n",
      " [9.4238e-02 0.0000e+00 1.4305e-06 ... 9.0137e-01 3.7861e-03 3.8981e-04]]\n",
      "[[1.2934e-04 1.2338e-04 1.6093e-06 ... 2.3365e-05 0.0000e+00 1.0000e+00]\n",
      " [3.6682e-02 7.7942e-02 5.1384e-03 ... 2.8820e-03 5.3644e-05 8.5742e-01]\n",
      " [1.6260e-03 6.4812e-03 4.7159e-04 ... 2.1782e-03 9.2480e-01 6.3965e-02]\n",
      " ...\n",
      " [2.3169e-01 1.6357e-01 1.9141e-01 ... 1.0986e-01 1.7452e-04 3.0103e-01]\n",
      " [9.3750e-01 5.9462e-04 6.4039e-04 ... 1.5640e-02 3.0014e-02 1.5701e-02]\n",
      " [1.4648e-02 5.9605e-08 1.5497e-06 ... 9.7998e-01 2.2590e-04 5.2872e-03]]\n",
      "[[1.915e-01 1.702e-01 3.311e-02 ... 2.805e-02 7.957e-03 5.122e-01]\n",
      " [9.880e-04 1.641e-03 8.321e-04 ... 1.247e-04 1.454e-03 8.568e-03]\n",
      " [1.028e-03 7.744e-03 1.016e-03 ... 5.447e-03 9.751e-01 6.470e-03]\n",
      " ...\n",
      " [2.980e-02 2.568e-01 9.058e-02 ... 6.531e-03 1.758e-02 3.745e-02]\n",
      " [5.190e-01 7.851e-03 6.372e-02 ... 3.638e-01 2.928e-02 4.951e-03]\n",
      " [1.768e-02 4.831e-02 3.967e-03 ... 4.480e-01 4.675e-01 1.454e-02]]\n",
      "[[5.673e-02 1.098e-01 4.292e-03 ... 1.454e-03 5.238e-03 7.866e-01]\n",
      " [6.557e-07 1.453e-04 3.994e-06 ... 1.788e-07 1.354e-04 7.348e-04]\n",
      " [5.960e-08 7.093e-06 2.444e-06 ... 1.192e-07 1.000e+00 1.311e-06]\n",
      " ...\n",
      " [8.766e-03 3.882e-01 2.850e-02 ... 3.149e-03 5.295e-03 1.007e-01]\n",
      " [7.417e-01 5.116e-03 1.080e-01 ... 7.397e-02 5.783e-02 2.634e-03]\n",
      " [1.606e-01 2.054e-01 5.322e-02 ... 1.449e-01 1.829e-01 1.263e-01]]\n",
      "[[4.163e-02 2.103e-02 1.439e-02 ... 1.190e-03 1.433e-04 9.185e-01]\n",
      " [5.051e-03 5.680e-03 3.199e-03 ... 1.383e-05 1.773e-03 4.407e-02]\n",
      " [5.307e-04 3.586e-02 6.493e-03 ... 2.942e-04 9.561e-01 5.307e-04]\n",
      " ...\n",
      " [4.022e-02 6.573e-02 8.789e-01 ... 6.428e-03 2.141e-04 3.578e-03]\n",
      " [8.926e-01 1.140e-03 9.863e-02 ... 6.924e-03 3.366e-04 1.919e-04]\n",
      " [1.823e-01 5.698e-02 8.740e-02 ... 3.137e-01 1.445e-02 3.118e-01]]\n",
      "[[1.576e-02 5.020e-02 3.021e-03 ... 5.674e-04 2.313e-05 9.092e-01]\n",
      " [9.646e-04 1.298e-03 8.779e-04 ... 5.609e-05 1.341e-05 2.577e-02]\n",
      " [2.414e-05 1.936e-02 2.964e-04 ... 1.699e-03 9.780e-01 7.439e-05]\n",
      " ...\n",
      " [3.729e-02 4.241e-01 3.613e-01 ... 3.796e-02 9.651e-03 6.915e-02]\n",
      " [8.882e-01 1.282e-02 3.062e-02 ... 4.636e-02 1.773e-02 9.174e-04]\n",
      " [5.646e-02 4.468e-01 3.342e-02 ... 2.354e-01 1.740e-02 1.768e-01]]\n",
      "[[1.7900e-03 6.2523e-03 2.5702e-04 ... 3.8803e-05 1.6689e-06 9.9121e-01]\n",
      " [1.1325e-06 1.5855e-05 9.5963e-06 ... 2.0862e-06 4.1723e-07 2.3155e-03]\n",
      " [0.0000e+00 8.2850e-06 2.3842e-07 ... 1.3709e-06 1.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [1.3292e-04 9.6533e-01 1.9140e-03 ... 7.3814e-04 2.0981e-02 6.0158e-03]\n",
      " [9.8535e-01 7.8559e-05 5.5790e-04 ... 1.3733e-02 3.5763e-07 7.1526e-07]\n",
      " [6.6711e-02 1.4807e-01 1.5038e-02 ... 6.4551e-01 1.4206e-02 1.0358e-01]]\n",
      "[[2.2793e-03 2.7599e-03 1.1796e-04 ... 4.1723e-06 1.2517e-06 9.9414e-01]\n",
      " [5.4836e-06 7.4506e-06 3.8147e-06 ... 1.1921e-07 1.7881e-07 1.9798e-03]\n",
      " [0.0000e+00 4.0054e-05 1.0729e-06 ... 7.7486e-07 1.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [6.7532e-05 9.7607e-01 2.6569e-03 ... 2.6464e-05 1.1368e-02 6.6423e-04]\n",
      " [9.9805e-01 6.6996e-05 4.7207e-04 ... 1.5726e-03 1.7881e-07 1.1921e-07]\n",
      " [2.3242e-01 1.7249e-01 2.5330e-02 ... 2.9053e-01 1.3892e-01 1.0046e-01]]\n",
      "[[8.4817e-05 9.8407e-05 2.1458e-06 ... 0.0000e+00 0.0000e+00 1.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 ... 0.0000e+00 0.0000e+00 2.0266e-06]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [6.9141e-06 9.7900e-01 1.7614e-03 ... 1.6689e-06 1.8494e-02 4.0174e-05]\n",
      " [1.0000e+00 0.0000e+00 6.3181e-06 ... 1.0806e-04 0.0000e+00 0.0000e+00]\n",
      " [2.2021e-01 3.2837e-02 2.6760e-03 ... 3.5889e-01 3.1177e-01 6.5857e-02]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6ae02b85884feb92f2c9f22140bbbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MistralForSequenceClassification were not initialized from the model checkpoint at HuggingFaceH4/zephyr-7b-beta and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,873,088 || all params: 7,117,533,184 || trainable%: 0.09656559122829936\n",
      "train shape: (3185, 5) valid shape: (791, 5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffec181cd9e24a6e97b3733d1306181f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3185 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c715efcc2e43839adaf647bd74683e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/791 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 2:13:30, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>6.207600</td>\n",
       "      <td>2.121094</td>\n",
       "      <td>2.010738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.089800</td>\n",
       "      <td>1.689453</td>\n",
       "      <td>1.658255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.252400</td>\n",
       "      <td>1.188477</td>\n",
       "      <td>1.176130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.101000</td>\n",
       "      <td>1.111328</td>\n",
       "      <td>1.109068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.799800</td>\n",
       "      <td>1.117188</td>\n",
       "      <td>1.111799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.728300</td>\n",
       "      <td>0.944824</td>\n",
       "      <td>0.937459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.333100</td>\n",
       "      <td>1.271484</td>\n",
       "      <td>1.218016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.313400</td>\n",
       "      <td>1.174805</td>\n",
       "      <td>1.113628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>1.545898</td>\n",
       "      <td>1.354563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.4918e-02 1.1841e-01 5.9662e-03 ... 1.6724e-02 2.8458e-02 5.4626e-02]\n",
      " [2.6749e-02 4.3915e-02 8.3374e-02 ... 2.8687e-02 1.1909e-02 1.7505e-01]\n",
      " [8.4543e-04 4.2877e-02 3.6216e-04 ... 3.4332e-05 5.2986e-03 1.1644e-03]\n",
      " ...\n",
      " [3.6694e-01 1.6320e-04 5.5075e-05 ... 2.1912e-01 3.6987e-01 4.4006e-02]\n",
      " [2.0248e-02 7.6416e-02 2.5589e-02 ... 4.8950e-02 2.4475e-02 7.9932e-01]\n",
      " [6.6772e-02 1.4038e-01 7.2899e-03 ... 6.5137e-01 9.7046e-03 1.0345e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajneesh/miniconda3/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.3508e-02 1.0452e-02 1.2012e-01 ... 1.9646e-03 4.1351e-02 1.0400e-01]\n",
      " [1.0729e-06 3.5882e-05 1.4186e-05 ... 1.2517e-06 9.9805e-01 7.3552e-05]\n",
      " [1.1903e-04 1.2481e-04 2.1720e-04 ... 3.5167e-06 2.3174e-03 1.8339e-03]\n",
      " ...\n",
      " [6.9385e-01 6.3896e-03 1.2061e-01 ... 2.4261e-02 5.3894e-02 6.7139e-02]\n",
      " [1.0107e-01 1.2436e-03 2.7075e-01 ... 1.6467e-01 5.6152e-03 4.4946e-01]\n",
      " [1.9873e-01 2.1286e-02 3.0786e-01 ... 2.2430e-02 1.2581e-02 2.6123e-01]]\n",
      "[[2.472e-03 3.088e-01 4.917e-03 ... 1.176e-03 1.487e-03 9.076e-02]\n",
      " [3.239e-03 5.539e-02 1.723e-02 ... 8.698e-03 5.195e-01 9.625e-02]\n",
      " [2.840e-04 1.357e-02 7.081e-04 ... 1.982e-04 7.701e-05 3.681e-03]\n",
      " ...\n",
      " [9.351e-02 2.676e-02 6.415e-02 ... 2.507e-01 3.635e-01 1.259e-01]\n",
      " [9.271e-02 1.181e-02 3.149e-01 ... 3.591e-01 2.419e-03 2.107e-01]\n",
      " [1.892e-01 4.758e-02 1.920e-01 ... 2.524e-01 9.636e-03 1.772e-01]]\n",
      "[[4.3945e-03 5.2441e-01 5.1613e-03 ... 3.0823e-03 1.3969e-02 5.0812e-02]\n",
      " [4.3511e-06 1.4484e-05 5.3644e-07 ... 9.5367e-07 1.0000e+00 5.8413e-06]\n",
      " [1.2076e-04 2.6436e-03 1.4567e-04 ... 3.5465e-05 2.3518e-03 6.5684e-05]\n",
      " ...\n",
      " [2.5024e-01 4.5776e-02 1.1566e-02 ... 7.6050e-02 5.5957e-01 2.1362e-02]\n",
      " [1.7993e-01 9.5596e-03 5.0598e-02 ... 6.9922e-01 2.2087e-03 5.1880e-02]\n",
      " [3.5156e-01 5.7373e-02 5.5023e-02 ... 3.7842e-01 5.4207e-03 6.1859e-02]]\n",
      "[[1.9324e-04 1.2164e-01 1.8112e-02 ... 1.4849e-03 9.3079e-03 1.1223e-02]\n",
      " [0.0000e+00 1.7881e-07 0.0000e+00 ... 0.0000e+00 1.0000e+00 3.5763e-07]\n",
      " [0.0000e+00 9.8348e-06 4.9472e-06 ... 5.9605e-08 7.2122e-06 1.1921e-07]\n",
      " ...\n",
      " [1.0040e-01 1.9348e-02 5.6519e-02 ... 3.1592e-01 4.0723e-01 9.1797e-02]\n",
      " [1.9516e-02 1.2696e-04 3.3051e-02 ... 9.4385e-01 3.9041e-05 3.7518e-03]\n",
      " [2.9678e-02 1.4658e-03 7.9224e-02 ... 8.7354e-01 7.6056e-04 1.2123e-02]]\n",
      "[[8.523e-05 3.317e-02 1.847e-04 ... 6.258e-06 4.361e-04 2.219e-02]\n",
      " [0.000e+00 4.709e-06 0.000e+00 ... 0.000e+00 1.000e+00 1.669e-06]\n",
      " [1.192e-07 2.384e-07 1.788e-07 ... 0.000e+00 1.788e-07 7.153e-07]\n",
      " ...\n",
      " [2.512e-01 1.651e-02 7.440e-02 ... 7.263e-02 5.454e-01 3.494e-02]\n",
      " [2.715e-01 9.527e-04 7.660e-02 ... 5.840e-01 1.238e-03 6.561e-02]\n",
      " [3.359e-01 5.775e-03 3.733e-01 ... 2.229e-01 3.477e-03 5.328e-02]]\n",
      "[[2.2054e-06 2.5425e-03 1.1265e-05 ... 5.9605e-08 7.6294e-06 7.0763e-03]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 5.9605e-08 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [1.0004e-01 5.7411e-04 1.6983e-02 ... 6.0539e-03 8.7451e-01 1.6298e-03]\n",
      " [2.5952e-01 0.0000e+00 5.8556e-04 ... 7.3926e-01 1.1921e-07 2.3115e-04]\n",
      " [6.8311e-01 1.9670e-06 1.4740e-02 ... 2.9956e-01 2.0981e-05 2.3136e-03]]\n",
      "[[5.9605e-08 8.7204e-03 3.5763e-07 ... 0.0000e+00 1.3709e-06 7.0343e-03]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [1.0925e-02 1.3781e-03 4.7827e-04 ... 2.0943e-03 9.8389e-01 1.4849e-03]\n",
      " [9.6680e-02 0.0000e+00 2.3234e-04 ... 9.0283e-01 0.0000e+00 5.3167e-04]\n",
      " [2.5610e-01 2.0325e-05 6.6528e-02 ... 6.7188e-01 5.3644e-06 5.3787e-03]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajneesh/miniconda3/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000e+00 7.2539e-05 0.0000e+00 ... 0.0000e+00 0.0000e+00 1.4091e-04]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [3.1853e-03 4.9472e-06 2.5988e-05 ... 1.1122e-04 9.9707e-01 1.0967e-05]\n",
      " [1.2726e-02 0.0000e+00 3.3975e-06 ... 9.8730e-01 0.0000e+00 5.9605e-07]\n",
      " [7.3853e-02 0.0000e+00 1.9424e-02 ... 9.0723e-01 0.0000e+00 2.3842e-05]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebae937e0d924cb0a5044662e06fe425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MistralForSequenceClassification were not initialized from the model checkpoint at HuggingFaceH4/zephyr-7b-beta and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,873,088 || all params: 7,117,533,184 || trainable%: 0.09656559122829936\n",
      "train shape: (3185, 5) valid shape: (791, 5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ad44932a854337ac7cc014c3772787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3185 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12927d0b215641ffa858b29fc6ed1462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/791 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 2:19:47, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.940600</td>\n",
       "      <td>2.626953</td>\n",
       "      <td>2.444725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.120900</td>\n",
       "      <td>1.535156</td>\n",
       "      <td>1.519947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.170000</td>\n",
       "      <td>1.206055</td>\n",
       "      <td>1.202628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>1.224609</td>\n",
       "      <td>1.212254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.725400</td>\n",
       "      <td>1.016602</td>\n",
       "      <td>1.014004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.900391</td>\n",
       "      <td>0.889808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>1.144531</td>\n",
       "      <td>1.087595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.296800</td>\n",
       "      <td>1.145508</td>\n",
       "      <td>1.074275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>1.741211</td>\n",
       "      <td>1.373249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2896   0.6274   0.009834 ... 0.0279   0.01455  0.001156]\n",
      " [0.4375   0.00735  0.05228  ... 0.2893   0.006145 0.198   ]\n",
      " [0.654    0.08026  0.00823  ... 0.05472  0.1084   0.02074 ]\n",
      " ...\n",
      " [0.82     0.01587  0.01     ... 0.03867  0.07745  0.004765]\n",
      " [0.03464  0.904    0.003551 ... 0.003782 0.0202   0.00935 ]\n",
      " [0.1819   0.132    0.007713 ... 0.002184 0.01087  0.0478  ]]\n",
      "[[0.0656   0.6836   0.05624  ... 0.0758   0.004147 0.00615 ]\n",
      " [0.371    0.1476   0.06033  ... 0.1936   0.05667  0.10736 ]\n",
      " [0.1848   0.216    0.1532   ... 0.07794  0.01245  0.04733 ]\n",
      " ...\n",
      " [0.29     0.1377   0.1661   ... 0.1935   0.009155 0.0554  ]\n",
      " [0.1376   0.521    0.0631   ... 0.04535  0.011375 0.08075 ]\n",
      " [0.1146   0.2236   0.04385  ... 0.01557  0.004375 0.1884  ]]\n",
      "[[3.458e-02 8.203e-02 3.047e-01 ... 5.483e-01 1.884e-04 5.272e-03]\n",
      " [3.032e-01 7.256e-03 1.771e-01 ... 4.612e-01 1.638e-03 3.726e-02]\n",
      " [1.644e-01 2.229e-02 2.098e-01 ... 4.966e-01 9.737e-04 5.316e-02]\n",
      " ...\n",
      " [1.020e-01 9.979e-03 2.004e-01 ... 6.396e-01 5.970e-04 2.403e-02]\n",
      " [1.422e-01 4.211e-01 1.969e-01 ... 1.965e-01 1.440e-04 4.242e-02]\n",
      " [2.522e-02 1.093e-01 5.606e-02 ... 6.313e-03 1.123e-03 7.739e-01]]\n",
      "[[8.7036e-02 2.8784e-01 3.6523e-01 ... 2.4292e-01 4.7159e-04 6.9427e-03]\n",
      " [2.9004e-01 4.7646e-03 1.0266e-01 ... 3.1128e-01 3.7909e-04 2.8906e-01]\n",
      " [2.2021e-01 6.3416e-02 2.4292e-01 ... 2.6831e-01 1.3542e-03 1.8958e-01]\n",
      " ...\n",
      " [1.7517e-01 9.0942e-02 2.2961e-01 ... 2.7002e-01 3.4451e-04 2.0764e-01]\n",
      " [1.0103e-04 9.3506e-01 6.8903e-05 ... 3.9935e-05 1.1683e-05 4.9957e-02]\n",
      " [4.7951e-03 3.8232e-01 3.2196e-03 ... 2.2640e-03 8.4591e-04 5.5420e-01]]\n",
      "[[7.782e-02 1.702e-03 6.475e-01 ... 2.722e-01 9.125e-05 2.570e-04]\n",
      " [4.353e-01 2.214e-03 1.295e-01 ... 2.045e-01 2.956e-03 2.250e-01]\n",
      " [2.024e-01 4.368e-03 5.332e-01 ... 2.527e-01 1.551e-03 3.960e-03]\n",
      " ...\n",
      " [2.255e-01 3.130e-03 2.070e-01 ... 5.605e-01 3.710e-04 2.680e-03]\n",
      " [9.631e-02 7.637e-01 8.734e-02 ... 1.683e-02 2.658e-05 3.531e-02]\n",
      " [7.092e-02 1.032e-01 1.666e-03 ... 1.120e-04 2.110e-02 7.764e-01]]\n",
      "[[5.2246e-02 1.4824e-02 4.0137e-01 ... 5.2979e-01 5.7364e-04 1.6057e-04]\n",
      " [5.2930e-01 3.0403e-03 1.8591e-01 ... 1.8335e-01 2.7466e-03 9.3628e-02]\n",
      " [1.6785e-01 5.6114e-03 2.5537e-01 ... 5.6152e-01 1.6794e-03 4.6501e-03]\n",
      " ...\n",
      " [2.2583e-01 1.6617e-02 1.2598e-01 ... 6.1035e-01 3.3236e-04 1.4458e-02]\n",
      " [9.8190e-03 8.7744e-01 4.3945e-03 ... 7.4425e-03 7.3254e-05 9.7473e-02]\n",
      " [2.4658e-02 1.0468e-01 7.8278e-03 ... 5.9414e-04 1.1539e-03 8.5596e-01]]\n",
      "[[3.0060e-03 9.2387e-06 8.4326e-01 ... 1.5356e-01 5.9605e-08 0.0000e+00]\n",
      " [2.7271e-01 1.7405e-05 3.2031e-01 ... 4.0161e-01 7.0989e-05 5.4436e-03]\n",
      " [5.9509e-02 1.2410e-04 4.3433e-01 ... 5.0195e-01 2.9802e-06 3.9101e-05]\n",
      " ...\n",
      " [1.4755e-02 5.6114e-03 5.5469e-01 ... 4.0576e-01 1.1921e-07 5.3453e-04]\n",
      " [2.6727e-04 9.9902e-01 2.1303e-04 ... 2.0623e-05 0.0000e+00 7.4208e-05]\n",
      " [1.6034e-05 9.0485e-03 1.1921e-05 ... 1.1921e-07 1.0729e-06 9.9023e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajneesh/miniconda3/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.2038e-03 2.2054e-06 9.7803e-01 ... 1.7639e-02 0.0000e+00 0.0000e+00]\n",
      " [6.8018e-01 3.9935e-06 1.0638e-01 ... 2.1167e-01 7.0751e-05 1.4648e-03]\n",
      " [8.0322e-02 1.4305e-05 7.6172e-01 ... 1.5784e-01 6.5565e-07 7.1526e-05]\n",
      " ...\n",
      " [1.1993e-01 2.6345e-04 1.8372e-01 ... 6.8750e-01 5.9605e-08 6.9580e-03]\n",
      " [8.8215e-04 9.9805e-01 1.8346e-04 ... 9.5367e-07 0.0000e+00 7.4005e-04]\n",
      " [3.4571e-06 6.5029e-05 5.3644e-07 ... 0.0000e+00 0.0000e+00 1.0000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajneesh/miniconda3/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.646e-05 0.000e+00 1.000e+00 ... 9.763e-05 0.000e+00 0.000e+00]\n",
      " [9.316e-01 0.000e+00 1.019e-02 ... 5.817e-02 3.576e-07 4.172e-07]\n",
      " [1.634e-02 0.000e+00 9.282e-01 ... 5.533e-02 0.000e+00 0.000e+00]\n",
      " ...\n",
      " [5.127e-02 1.669e-06 2.791e-01 ... 6.699e-01 0.000e+00 1.192e-07]\n",
      " [7.153e-06 1.000e+00 9.537e-07 ... 0.000e+00 0.000e+00 2.503e-06]\n",
      " [0.000e+00 3.022e-05 0.000e+00 ... 0.000e+00 0.000e+00 1.000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajneesh/miniconda3/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for f in range(5):\n",
    "    run(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b98d0068-d589-49cf-943e-e1a7a1e5512a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0e01d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25499629-2ce8-4f84-85ff-4802e87bd52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17aa64bbeee46faac7de785a6e63b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples, max_length=CFG.max_len):\n",
    "    return tokenizer(examples[\"all_text\"], \n",
    "                     truncation=True, \n",
    "                     max_length=max_length, \n",
    "                     padding=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.TARGET_MODEL, use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "test_ds = Dataset.from_pandas(test)\n",
    "test_tokenized_ds = test_ds.map(preprocess_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29defacb-14e2-4b3d-992c-30b4d0c679aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35ba635d-1a00-47bd-847b-ea408f5e15e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79fd805da5ea4001b3898ecd2cbeaf6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MistralForSequenceClassification were not initialized from the model checkpoint at HuggingFaceH4/zephyr-7b-beta and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = MistralForSequenceClassification.from_pretrained(\n",
    "    CFG.TARGET_MODEL,\n",
    "    num_labels=7,\n",
    "    cache_dir='///mnt/c/Personal/Competitions/HFCache/',\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\":0})\n",
    "\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa77916d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Fold: 0 ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Fold: 2 ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Fold: 3 ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Fold: 4 ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy\n",
    "out = np.zeros((1001, 7))\n",
    "for f in [0,2,3,4]:#(range(5)): fold 1 was really bad\n",
    "    print(f'----------- Fold: {f} ----------')\n",
    "    model = PeftModel.from_pretrained(base_model, f'///mnt/c/Personal/Competitions/Kaggle/h2oai-predict-the-llm/runs/nb006/{f}/')\n",
    "\n",
    "    trainer = Trainer(model=model,\n",
    "                      tokenizer=tokenizer,\n",
    "                      data_collator=data_collator)\n",
    "    pred_output = trainer.predict(test_tokenized_ds)\n",
    "    logits = pred_output.predictions\n",
    "    probits = scipy.special.softmax(logits,1)\n",
    "\n",
    "    out += probits/4\n",
    "    del trainer, model\n",
    "    torch.cuda.empty_cache()    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78953ef0-e3b9-46a3-b5d5-f7098050cf15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.42165565e-01, 9.00506973e-03, 6.56509399e-02, ...,\n",
       "        5.36315918e-01, 1.26384676e-01, 1.90911293e-02],\n",
       "       [1.37627125e-04, 4.68301773e-03, 5.76376915e-05, ...,\n",
       "        2.79188156e-04, 9.94506836e-01, 4.95254993e-04],\n",
       "       [1.19209290e-07, 5.96046448e-07, 5.96046448e-08, ...,\n",
       "        4.76837158e-07, 1.00000000e+00, 5.96046448e-08],\n",
       "       ...,\n",
       "       [4.92553711e-02, 1.31215096e-01, 3.27293396e-01, ...,\n",
       "        2.95013428e-01, 1.61668360e-01, 3.06643844e-02],\n",
       "       [3.54125977e-01, 1.47848129e-02, 3.08013916e-01, ...,\n",
       "        3.07586670e-01, 2.63869762e-04, 1.32680535e-02],\n",
       "       [2.23785639e-03, 9.34197903e-02, 1.60312653e-03, ...,\n",
       "        1.09428167e-03, 5.06639481e-05, 9.01489258e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "169304e4-25bf-4a25-96b4-ccd1c0b0b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.iloc[:,1:] = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e8104e5-6474-42c6-b02c-897423f11736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'///mnt/c/Personal/Competitions/Kaggle/h2oai-predict-the-llm/runs/nb006/'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6b89634-d2dc-4bc1-93d2-a635281492ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(f'{OUTPUT_DIR}/submit.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14d8f3b-8b87-40ff-be15-676a7928046c",
   "metadata": {},
   "source": [
    "### Smaller max len inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0ad4d96-6b14-4d33-9b82-bd269079672b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5335ead9a9e42b1b4ac4e7fce867b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples, max_length=1536):\n",
    "    return tokenizer(examples[\"all_text\"], \n",
    "                     truncation=True, \n",
    "                     max_length=max_length, \n",
    "                     padding=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.TARGET_MODEL, use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "test_ds = Dataset.from_pandas(test)\n",
    "test_tokenized_ds = test_ds.map(preprocess_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdfe200d-160b-467e-928c-0a09fd06c91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b0807f1-2090-4b4a-b614-5db9c18c4043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e831f95803c472b80e209e9d640de33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MistralForSequenceClassification were not initialized from the model checkpoint at HuggingFaceH4/zephyr-7b-beta and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = MistralForSequenceClassification.from_pretrained(\n",
    "    CFG.TARGET_MODEL,\n",
    "    num_labels=7,\n",
    "    cache_dir='///mnt/c/Personal/Competitions/HFCache/',\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\":0})\n",
    "\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "165e712f-54f4-455d-8f54-af9bda1c33dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Fold: 0 ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Fold: 2 ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Fold: 3 ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Fold: 4 ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy\n",
    "out = np.zeros((1001, 7))\n",
    "for f in [0,2,3,4]:#(range(5)): fold 1 was really bad\n",
    "    print(f'----------- Fold: {f} ----------')\n",
    "    model = PeftModel.from_pretrained(base_model, f'///mnt/c/Personal/Competitions/Kaggle/h2oai-predict-the-llm/runs/nb006/{f}/')\n",
    "\n",
    "    trainer = Trainer(model=model,\n",
    "                      tokenizer=tokenizer,\n",
    "                      data_collator=data_collator)\n",
    "    pred_output = trainer.predict(test_tokenized_ds)\n",
    "    logits = pred_output.predictions\n",
    "    probits = scipy.special.softmax(logits,1)\n",
    "\n",
    "    out += probits/4\n",
    "    del trainer, model\n",
    "    torch.cuda.empty_cache()    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb216e06-bea6-45a2-b1a6-444caa76c634",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.iloc[:,1:] = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be5f0864-87ce-4fdd-af27-05fd780ef143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission.to_csv(f'{OUTPUT_DIR}/submit_maxlenX2.csv',index=False)\n",
    "sample_submission.to_csv(f'{OUTPUT_DIR}/submit_maxlen_1536.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71193063-ccb2-4696-bb0d-79cfee32b0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
